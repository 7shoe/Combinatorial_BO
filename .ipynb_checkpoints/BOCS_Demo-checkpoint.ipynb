{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0cce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple, List, Iterable, Callable\n",
    "\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import halfcauchy, invgamma\n",
    "import cvxpy as cp\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from numpy.random import default_rng\n",
    "from itertools import chain, combinations, product\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a767b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(x:Iterable):\n",
    "    '''\n",
    "    Powerset (set of subsets) for a given iterable x incl. âˆ…\n",
    "    '''\n",
    "    s = list(x)\n",
    "    powerSet = chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "    \n",
    "    return list(powerSet)\n",
    "\n",
    "class Oracle:\n",
    "    def __init__(self, fun, sigma_2:float=0.0, N_total:int=100_000, seed:int=0):\n",
    "        assert isinstance(fun, Callable), \"Input `f` must be a callable function.\"\n",
    "        assert isinstance(sigma_2, float) and sigma_2>=0, \"Input `sigma_2` must be a non-negative float.\"\n",
    "        assert isinstance(seed, int), \"Input `seed` must be an integer.\"\n",
    "        \n",
    "        self.fun = fun\n",
    "        self.sigma_2 = sigma_2\n",
    "        self.seed = seed\n",
    "        self.N_total = N_total\n",
    "        self.N_current = 0\n",
    "        \n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "    def __expandX__(self, x:np.array) -> np.array:\n",
    "        '''\n",
    "        Expand original input format {1,...,d} -> {0} + {1,...,d} + {... (d over 2) ... }\n",
    "        '''\n",
    "        \n",
    "        # transform\n",
    "        if(len(x.shape)==2 and len(x)>1):\n",
    "            quad_x = np.stack([x[:,pair[0]] * x[:,pair[1]] for pair in powerset(range(x.shape[1])) if len(pair)==2], axis=1)\n",
    "            assert len(quad_x)==len(x) and math.comb(len(x), 2), \"Inconsistent dimension for the resulting design matrix of quadratic terms\"\n",
    "            x = np.concatenate((x, quad_x), axis=1)\n",
    "        else:\n",
    "            x = np.array(list(x) + [float(x[pair[0]] * x[pair[1]]) for pair in powerset(range(len(x))) if len(pair)==2])\n",
    "            x = np.array([1] + list(x), dtype=float)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def f(self, x:np.array, noiseFlag:bool=True):\n",
    "        '''\n",
    "        Returns (noisy) function value of function f\n",
    "        '''\n",
    "    \n",
    "        # expand raw input\n",
    "        x = self.__expandX__(x)\n",
    "        \n",
    "        if(len(x.shape)==2 and len(x)>1):\n",
    "            assert self.N_current + len(x) <= self.N_total, f\"Limit of `N_total`={self.N_total} will be exceeded as {self.N_current} calls where made and this request requires another {len(x)} function calls.\"\n",
    "            self.N_current += len(x)\n",
    "            if(noiseFlag):\n",
    "                return np.array([self.fun(x_) for x_ in x]) + np.random.normal(loc=0, scale=np.sqrt(self.sigma_2), size=len(x))\n",
    "            else:\n",
    "                return np.array([self.fun(x_) for x_ in x])\n",
    "        else:\n",
    "            assert self.N_current + 1 <= self.N_total, f\"Limit of `N_total`={self.N_total} will be exceeded as {self.N_current} calls where made and this request requires another {len(X)} function calls.\"\n",
    "            self.N_current += 1\n",
    "            if(noiseFlag):\n",
    "                return self.fun(x)+float(np.random.normal(loc=0, scale=np.sqrt(self.sigma_2), size=1))\n",
    "            return self.fun(x)\n",
    "        \n",
    "class SparseBayesReg:\n",
    "\n",
    "    d_MAX = 20\n",
    "    \n",
    "    def __init__(self, N_total:int, seed:int, burnin:int, thinning:int):\n",
    "\n",
    "        assert isinstance(seed, int), \"`seed` must be an integer.\"\n",
    "        assert isinstance(burnin, int) and burnin>=0, \"`burnin` must be a non-negative integer.\"\n",
    "        assert isinstance(thinning, int) and thinning>=1, \"`thinning` must be an positive integer.\"\n",
    "        \n",
    "        # - assignment\n",
    "        self.N_total = N_total\n",
    "        self.seed = seed\n",
    "        self.burnin = burnin\n",
    "        self.thinning = thinning\n",
    "        \n",
    "    def setXy(self, X:np.array, y:np.array) -> None:\n",
    "        '''\n",
    "        Setup of design matrix X (standardized, incl. leading 1-column and quadratic terms) and target vector y (transalted to E[y]=0)\n",
    "        '''\n",
    "        assert sum(X[:,0])!=len(X), \"Provide the design matrix X without adding a leading 1-column (for intercept)\"\n",
    "        \n",
    "        self.d = X.shape[1]\n",
    "        self.p = 1 + self.d + math.comb(self.d, 2)\n",
    "        \n",
    "        assert isinstance(self.d, int) and 0<self.d<=self.d_MAX, f\"The inferred dimension `d`={self.d} should be smaller than {self.d_MAX}\"\n",
    "        \n",
    "        self.__expandX__(X)\n",
    "        self.__standardizeX__()\n",
    "        self.__standardizeX__()\n",
    "        self.__interceptColumnX__()\n",
    "\n",
    "        self.__translateY__(y)\n",
    "    \n",
    "    def __expandX__(self, X:np.array) -> None:\n",
    "        '''\n",
    "        Given a (binary) design matrix X, it appends pairwise products of columns and appends to the design matrix X;\n",
    "        *excluding* the leading intercept column of 1's\n",
    "        '''\n",
    "        \n",
    "        # quadratic terms\n",
    "        quad_X = np.stack([X[:,pair[0]] * X[:,pair[1]] for pair in powerset(range(X.shape[1])) if len(pair)==2], axis=1)\n",
    "\n",
    "        assert len(quad_X)==len(X) and math.comb(len(X), 2), \"Inconsistent dimension for the resulting design matrix of quadratic terms\"\n",
    "\n",
    "        self.X = np.concatenate((X, quad_X), axis=1)\n",
    "\n",
    "    def __standardizeX__(self) -> None:\n",
    "        '''\n",
    "        Standardizes (translates & rescales) the columns of the design matrix (input matrix) \n",
    "        '''\n",
    "\n",
    "        X = self.X\n",
    "        assert X.shape[1]==self.p-1, \"The given design matrix includes a leading 1-column; unclear if it is a legitimiate (coincidental) feature or leading 1 column was already incldued\"\n",
    "\n",
    "        X_mu, X_sigma = X.mean(axis=0), X.std(axis=0)\n",
    "        X_new = (X - X_mu) /  X_sigma\n",
    "\n",
    "        self.X_mu = X_mu\n",
    "        self.X_sigma = X_sigma #np.sqrt(len(X)) * X_sigma  # corrected for sqrt(n)\n",
    "        self.X = X_new\n",
    "        \n",
    "    def __interceptColumnX__(self) -> np.array:\n",
    "        '''\n",
    "        Adds a leading vector of 1s to the binary matrix X (of 1st and 2nd order interactions)\n",
    "        '''\n",
    "        \n",
    "        X = self.X\n",
    "        X = np.concatenate((np.ones_like(X[:,0]).reshape(-1,1), X), axis=1)\n",
    "\n",
    "        assert X.shape[1]==self.p, \"Inconsistent number of columns after adding leading 1-col\"\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "    def __translateY__(self, y:np.array) -> None:\n",
    "        '''\n",
    "        Translation of the target vector y such that priori condition E[y]=0 is satisfied.\n",
    "        (No rescaling to unit variance is applied, though.)\n",
    "        '''\n",
    "        X = self.X\n",
    "\n",
    "        assert len(X) == len(y), \"Length of target vector y does not coincide with design matrix X\"\n",
    "\n",
    "        # Standardize y's\n",
    "        y_mu = np.mean(y)\n",
    "        y_new = y - y_mu\n",
    "        \n",
    "        self.y_mu = y_mu\n",
    "        self.y = y_new\n",
    "        \n",
    "    def add(self, x_new:np.array, y_new:float, fitFlag:bool=True) -> None:\n",
    "        '''\n",
    "        Appends new datapoint to X,y\n",
    "        '''\n",
    "\n",
    "        assert len(x_new.shape)==1 and len(x_new)==self.d, f\"Input has dimension {x_new.shape} but ({self.d},) was expected.\"\n",
    "\n",
    "        # X : expand, standardize, append leading 1\n",
    "        x_new_exp = np.array(list(x_new) + [float(x_new[pair[0]] * x_new[pair[1]]) for pair in powerset(range(len(x_new))) if len(pair)==2])\n",
    "        x_new_exp = (x_new_exp - self.X_mu) / self.X_sigma\n",
    "        \n",
    "        x_new_exp = np.array([1] + list(x_new_exp), dtype=float)\n",
    "        self.X = np.append(arr=self.X, values=x_new_exp.reshape(1,-1), axis=0)\n",
    "\n",
    "        # de-bias\n",
    "        self.y = np.append(arr=self.y, values=(y_new - self.y_mu))\n",
    "        \n",
    "        # re-fit\n",
    "        if(fitFlag):\n",
    "            self.__fit__()\n",
    "    \n",
    "    def __mvg__(self, Phi, alpha, D):\n",
    "        '''\n",
    "        Sample multivariate Gaussian (independent of d) from NumPy\n",
    "        Not used Rue (2001) or et. al. (2015) approaches on fast sampling mvg\n",
    "        N(mean = S@Phi.T@y, cov = inv(Phi'Phi + inv(D))\n",
    "        '''\n",
    "        #assert len(Phi.shape)==2 and Phi.shape[0]==Phi.shape[1], \"`Phi` must be a quadratic matrix.\"\n",
    "        assert len(D.shape)==2 and D.shape[0]==D.shape[1], \"`D` must be a quadratic matrix.\"\n",
    "        \n",
    "        S = np.linalg.inv(Phi.T @ Phi + np.linalg.inv(D))\n",
    "        x = np.random.multivariate_normal(mean=((S @ Phi.T) @ y), cov=S, size=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def sampleAlpha(self) -> np.array:\n",
    "        '''\n",
    "        Samples posterior  ~ P( |X,y) from (most current) posterior distribution\n",
    "        '''\n",
    "        alpha_post = np.random.multivariate_normal(mean = self.alpha_mu,\n",
    "                                                   cov  = self.alpha_cov,\n",
    "                                                   size = 1).reshape(-1)\n",
    "        \n",
    "        return alpha_post\n",
    "    \n",
    "    def __fit__(self) -> None:\n",
    "        '''\n",
    "        Core of fitting procedure (on self.X, self.y)\n",
    "        '''\n",
    "        \n",
    "        # D0\n",
    "        self.n = len(self.X)\n",
    "        \n",
    "        # setup values\n",
    "        alphas_out = np.zeros((self.p, 1))\n",
    "        s2_out     = np.zeros((1, 1))\n",
    "        t2_out     = np.zeros((1, 1))\n",
    "        l2_out     = np.zeros((self.p, 1))\n",
    "\n",
    "        # sample priors\n",
    "        betas   = halfcauchy.rvs(size=self.p) \n",
    "        tau_2   = halfcauchy.rvs(size=1)                            \n",
    "        nu      = np.ones(self.p) # ?\n",
    " \n",
    "        sigma_2, xi = 1.0, 1.0\n",
    "        \n",
    "        # Gibbs sampler\n",
    "        for k in range(self.N_total):\n",
    "            #print('k=')\n",
    "            # std. deviation\n",
    "            sigma = np.sqrt(sigma_2)\n",
    "\n",
    "            # alphas\n",
    "            # - Sigma_star\n",
    "            Sigma_star = tau_2 * np.diag(betas**2) # Sigma_star\n",
    "            Sigma_star_inv = np.linalg.inv(Sigma_star)\n",
    "            # - A\n",
    "            A     = (self.X.T @ self.X) + Sigma_star_inv\n",
    "            A_inv = np.linalg.inv(A)\n",
    "            \n",
    "            # - update posterior mean, cov\n",
    "            self.alpha_mu  = A_inv @ self.X.T @ self.y\n",
    "            self.alpha_cov = sigma_2 * A_inv\n",
    "            # - sample alpha\n",
    "            alphas = self.sampleAlpha()\n",
    "            \n",
    "            # sigma_2\n",
    "            sigma_2 = invgamma.rvs(0.5*(self.n+self.p), scale=0.5*(np.linalg.norm((self.y - self.X @ alphas), 2)**2 + (alphas.T @ Sigma_star_inv @ alphas)))\n",
    "\n",
    "            \n",
    "            # - betas\n",
    "            betas_2 = invgamma.rvs(np.ones(self.p), scale=(1. / nu) + (alphas**2)/(2 * sigma_2 * tau_2))\n",
    "            betas = np.sqrt(betas_2)\n",
    "\n",
    "            # - tau_2\n",
    "            tau_2 = invgamma.rvs(0.5*(self.p+1), scale=1.0 / xi + (1. / (2. * sigma_2)) * sum(alphas**2 / betas**2), size=1)\n",
    "\n",
    "            # - nu\n",
    "            nu = invgamma.rvs(np.ones(self.p), scale=1.0 + betas**(-2), size=self.p)\n",
    "\n",
    "            # - xi\n",
    "            xi = invgamma.rvs(1.0, scale=1.0 + 1.0 / tau_2, size=1)\n",
    "            \n",
    "            # store samples\n",
    "            if k > self.burnin:\n",
    "                # - append\n",
    "                if(k%self.thinning==0):\n",
    "                    alphas_out = np.append(arr=alphas_out, values=alphas.reshape(-1,1), axis=1)\n",
    "                    s2_out = np.append(s2_out, sigma_2)\n",
    "                    t2_out = np.append(t2_out, tau_2)\n",
    "                    l2_out = np.append(arr=l2_out, values=betas.reshape(-1,1), axis=1)\n",
    "\n",
    "        # Clip 1st value\n",
    "        self.alphas = alphas_out[:,1:]\n",
    "        self.s2 = s2_out[1:]\n",
    "        self.t2 = t2_out[1:]\n",
    "        self.l2 = l2_out[1:]\n",
    "        \n",
    "    def getAlphas(self) -> np.array:\n",
    "        '''\n",
    "        Returns current array of alpha posterior samples\n",
    "        '''\n",
    "        return self.alphas\n",
    "    \n",
    "    def fit(self, X:np.array, y:np.array) -> None:\n",
    "        '''\n",
    "        Fitting the (initial) model on the data D0={X0,y0}\n",
    "        '''\n",
    "        assert len(X.shape)==2 and len(y.shape)==1, \"Design matrix X and target vector y.\"\n",
    "        assert X.shape[0]==len(y), f\"Dimension of design matrix X and target vector y do not coincide: X.shape[1]={X.shape[1]}!={len(y)}=len(y)\"\n",
    "        assert len(X) < self.N_total, f\"Implied `N_init`=len(X)={len(X)} exceeds `N_total`={self.N_total}.\"\n",
    "        \n",
    "        # setup\n",
    "        self.setXy(X, y)\n",
    "        \n",
    "        # fitting\n",
    "        self.__fit__()\n",
    "        \n",
    "        \n",
    "\n",
    "class SDP:\n",
    "    penOrdList = [1, 2]\n",
    "    optModes = ['min', 'max']\n",
    "    d_MAX = 20\n",
    "    \n",
    "    def __init__(self, alpha:np.array, lambd:float=0.1, pen_ord:int=2, mode:str='min') -> List[np.array]:\n",
    "        \n",
    "        assert isinstance(mode, str), \"Input `mode` must be a str either `min` or `max`.\"\n",
    "        mode = mode.lower()\n",
    "        assert mode in self.optModes, \"Input `mode` is str. In addition, it must be a str either `min` or `max`.\"\n",
    "        assert isinstance(lambd, float) and lambd >=0, \"lambda (regularization parameter) must be non-negative scalar.\"\n",
    "        assert pen_ord in self.penOrdList, \"Only l=1 or l=2 supported for `pen_ord`\"\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.lambd = lambd\n",
    "        self.pen_ord = pen_ord\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # infer d(imension)\n",
    "        self.p = len(self.alpha)\n",
    "        dDict = {1+dLoc+math.comb(dLoc,2) : dLoc for dLoc in range(1,self.d_MAX+1)}\n",
    "        if(self.p in dDict.keys()):\n",
    "            self.d = dDict[self.p]\n",
    "        else:\n",
    "            assert False, f'Length of `alpha` is not a 1+d+binom(d,2) for any 1,2,...,{self.d_MAX}'\n",
    "        assert isinstance(self.d, int), \"Dimension `d` must be non-negative integer.\"\n",
    "        \n",
    "        #print('self...d: ', self.d)\n",
    "        \n",
    "        # extract 1st/2nd order terms\n",
    "        b = self.alpha[1:1 + self.d]  # 1st\n",
    "        a = self.alpha[1 + self.d:]   # 2nd\n",
    "\n",
    "        # get indices for quadratic terms\n",
    "        idx_prod = np.array(list(combinations(np.arange(self.d), 2)))\n",
    "        d_idx = idx_prod.shape[0]\n",
    "\n",
    "        # check number of coefficients\n",
    "        if len(a)!=d_idx:\n",
    "            assert False, 'Number of Coefficients does not match indices!'\n",
    "\n",
    "        # xAx-term\n",
    "        A = np.zeros((self.d, self.d))\n",
    "        for i in range(d_idx):\n",
    "            A[idx_prod[i,0], idx_prod[i,1]] = 0.5 * a[i]\n",
    "        A += A.T\n",
    "\n",
    "        # bx-term\n",
    "        bt = 0.5 * (b + A @ np.ones(self.d)).reshape((-1, 1))\n",
    "        bt = bt.reshape((self.d, 1))\n",
    "        At = np.vstack((np.append(0.25*A, 0.25*bt, axis=1), np.append(bt.T, 2.)))\n",
    "        \n",
    "        self.A  = A\n",
    "        self.b  = b\n",
    "        self.At = At\n",
    "        self.bt = bt\n",
    "        \n",
    "    def run(self) -> np.array:\n",
    "        '''\n",
    "        Runs the BQP-relaxation, SDP-optimization, and extracts candidate x via geometric rounding\n",
    "        '''\n",
    "        self.solve()\n",
    "        self.decompose()\n",
    "        return self.geometricRounding()\n",
    "        \n",
    "        \n",
    "    def solve(self, ) -> None:\n",
    "        '''Solve SDP'''\n",
    "        # SDP relaxation\n",
    "        Xvar = cp.Variable((self.d+1, self.d+1), PSD=True)\n",
    "        \n",
    "        # - objective function\n",
    "        if(self.mode=='min'):\n",
    "            f0 = cp.Minimize(cp.trace((self.At @ Xvar)))\n",
    "        else:\n",
    "            f0 = cp.Maximize(cp.trace((self.At @ Xvar)))\n",
    "        \n",
    "        # - constraints\n",
    "        constraints = [cp.diag(Xvar) == np.ones(self.d+1)]\n",
    "        prob = cp.Problem(f0, constraints)\n",
    "        prob.solve()\n",
    "        \n",
    "        self.Xvar = Xvar\n",
    "        \n",
    "    def decompose(self) -> None:\n",
    "        '''\n",
    "        Wrapper for stable Cholesky decomposition\n",
    "        '''\n",
    "        self.L = self.__stableCholesky__(eTol=1E-12)\n",
    "    \n",
    "    def __stableCholesky__(self, eTol:float=1E-10) -> np.array:\n",
    "        '''\n",
    "        Performs numerically stable Cholesky decomposition (by adding regularity to the matrix until PSD). \n",
    "        '''\n",
    "        try:\n",
    "            return np.linalg.cholesky(self.Xvar.value + eTol*np.eye(self.Xvar.value.shape[0]))\n",
    "        except Exception as e:\n",
    "            if(isinstance(e, np.linalg.LinAlgError)):\n",
    "                return self.__stableCholesky__(10*eTol)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    def geometricRounding(self, k_rounds:int=100) -> np.array:\n",
    "        '''\n",
    "        Random geometric round and conversion to original space\n",
    "        - k_rounds: number of iterations\n",
    "        '''\n",
    "        x_cand  = np.zeros((self.d, k_rounds))\n",
    "        f_star  = np.zeros(k_rounds)\n",
    "\n",
    "        for j in range(k_rounds):\n",
    "            # rnd cutting plane vector (U on Sn) \n",
    "            r = np.random.randn(self.d+1)\n",
    "            r /= np.linalg.norm(r, ord=2)\n",
    "            \n",
    "            # rnd hyperplane\n",
    "            y_star = np.sign(self.L.T @ r)\n",
    "\n",
    "            # convert solution to original domain and assign to output vector\n",
    "            x_cand[:,j] = 0.5 * (1.0 + y_star[:self.d])\n",
    "            f_star[j] = (x_cand[:,j].T @ self.A @ x_cand[:,j]) + (self.b @  x_cand[:,j])\n",
    "\n",
    "            # Find optimal rounded solution\n",
    "            if(self.mode=='min'):\n",
    "                f_argopt = np.argmin(f_star)\n",
    "            else:\n",
    "                f_argopt = np.argmax(f_star)\n",
    "            x_0      = x_cand[:,f_argopt]\n",
    "            f_0      = f_star[f_argopt]\n",
    "\n",
    "        return (x_0, f_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eafff3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BOCS:\n",
    "    variantList = ['SDP', 'SA']\n",
    "    \n",
    "    def __init__(self, variant:str='SDP', oracle:Oracle, N:int, B:int=0, T:int=1, seed:int=0,\n",
    "                 lambd:float=0.5, pen_ord:int=2, mode:str='min'):\n",
    "        \n",
    "        assert variant is in self.variantList, f\"AFO `variant` must be in: {', '.join(variantList)}\"\n",
    "        \n",
    "        self.variant = variant\n",
    "        self.N = N\n",
    "        self.seed = seed\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        self.lambd = lambd\n",
    "        self.pen_ord = pen_ord\n",
    "        self.mode = mode\n",
    "        self.oracle = oracle\n",
    "        \n",
    "        # init Sparse Bayesian Regression\n",
    "        self.BayReg = SparseBayesReg(N_total=self.N, burnin=self.B, thinning=self.T, seed=self.seed)\n",
    "        \n",
    "    def fit(self, X:np.array, y:np.array) -> None:\n",
    "        '''\n",
    "        Delegate fit to bayesian regression model\n",
    "        '''\n",
    "        self.BayReg.setXy(X,y)\n",
    "        self.BayReg.fit(X,y)\n",
    "        \n",
    "    def update(self,):\n",
    "        '''\n",
    "        Sample alpha from Bayesian regression, solve SDP, return cancidate x & (noisy) oracle function value y\n",
    "        '''\n",
    "        alpha_t = self.BayReg.sampleAlpha()\n",
    "        \n",
    "        # SDP update\n",
    "        if(self.variant=='SDP'):\n",
    "            self.sdp = SDP(alpha=alpha_t, lambd=self.lambd, pen_ord=self.pen_ord, mode=self.mode)\n",
    "            x_new, y_new_hat = self.sdp.run()\n",
    "            y_new = self.oracle.f(x_new)\n",
    "        \n",
    "        # update model\n",
    "        self.BayReg.add(x_new, y_new)\n",
    "        \n",
    "        return x_new, y_new\n",
    "    \n",
    "class RandomSearch():\n",
    "    d_MAX = 20\n",
    "    \n",
    "    def __init__(self, oracle:Oracle, d:int, seed:int=0):\n",
    "        assert isinstance(d, int) and 0<d<self.d_MAX, f\"Dimension `d` must be non-negative integer smaller than {self.d_MAX}\"\n",
    "        \n",
    "        self.oracle = oracle\n",
    "        self.d = d\n",
    "        self.seed = seed\n",
    "        \n",
    "        np.random.seed(self.seed)\n",
    "    \n",
    "    def update(self,):\n",
    "        '''\n",
    "        Sample random x (& noisy oracle function value) y\n",
    "        '''\n",
    "        x_new = np.random.binomial(n=1, p=0.5, size=self.d)\n",
    "        y_new = self.oracle.f(x=x_new)\n",
    "        return x_new, y_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db1866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare vectors to save solutions\n",
    "class SA:\n",
    "    def __init__(self, N:int, self.d:int, T:float=0.8):\n",
    "        assert isinstance(T, float) and 0<T<1.0, \"Temperature parameter `T` must be in (0.0, 1.0)\"\n",
    "        \n",
    "        self.N = N\n",
    "        self.d = d\n",
    "        self.T = T\n",
    "        \n",
    "        model_iter = np.zeros((self.N, self.d))\n",
    "        obj_iter   = np.zeros(n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b363b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated Annealing Update\n",
    "# Extract inputs\n",
    "\tn_vars = inputs['n_vars']\n",
    "\tn_iter = inputs['evalBudget']\n",
    "\n",
    "\t# Declare vectors to save solutions\n",
    "\tmodel_iter = np.zeros((n_iter,n_vars))\n",
    "\tobj_iter   = np.zeros(n_iter)\n",
    "\n",
    "\t# Set initial temperature and cooling schedule\n",
    "\tT = 1.\n",
    "\tcool = lambda T: .8*T\n",
    "\n",
    "\t# Set initial condition and evaluate objective\n",
    "\told_x   = sample_models(1,n_vars)\n",
    "\told_obj = objective(old_x)\n",
    "\n",
    "\t# Set best_x and best_obj\n",
    "\tbest_x   = old_x\n",
    "\tbest_obj = old_obj\n",
    "\n",
    "\t# Run simulated annealing\n",
    "\tfor t in range(n_iter):\n",
    "\n",
    "\t\t# Decrease T according to cooling schedule\n",
    "\t\tT = cool(T)\n",
    "\n",
    "\t\t# Find new sample\n",
    "\t\tflip_bit = np.random.randint(n_vars)\n",
    "\t\tnew_x = old_x.copy()\n",
    "\t\tnew_x[0,flip_bit] = 1. - new_x[0,flip_bit]\n",
    "\n",
    "\t\t# Evaluate objective function\n",
    "\t\tnew_obj = objective(new_x)\n",
    "\n",
    "\t\t# Update current solution iterate\n",
    "\t\tif (new_obj < old_obj) or (np.random.rand() < np.exp( (old_obj - new_obj)/T )):\n",
    "\t\t\told_x   = new_x\n",
    "\t\t\told_obj = new_obj\n",
    "\n",
    "\t\t# Update best solution\n",
    "\t\tif new_obj < best_obj:\n",
    "\t\t\tbest_x   = new_x\n",
    "\t\t\tbest_obj = new_obj\n",
    "\n",
    "\t\t# save solution\n",
    "\t\tmodel_iter[t,:] = best_x\n",
    "\t\tobj_iter[t]\t\t= best_obj\n",
    "\n",
    "\treturn (model_iter, obj_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3929bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequentist Version\n",
    "# - - - - - - - - - - -\n",
    "# Problem\n",
    "d  = 10\n",
    "n  = 30\n",
    "n1 = 100\n",
    "\n",
    "# oracle\n",
    "coef = np.random.normal(loc=0, scale=5, size=1+d+math.comb(d,2))\n",
    "orc1 = Oracle(fun= lambda x: sum([coef[i] * x[i] for i in range(len(x)-1)]), sigma_2=3.0, N_total=100_000_000)\n",
    "\n",
    "# D0\n",
    "X = np.random.binomial(n=1,p=0.5, size=n*d).reshape((n,d))\n",
    "y = orc1.f(X)\n",
    "\n",
    "#\n",
    "dictBOCS = dict{}\n",
    "dictRND = dict{}\n",
    "for j in range(15): \n",
    "\n",
    "    # BOCS\n",
    "    bocs = BOCS(oracle=orc1, N=200, B=10, T=2)\n",
    "    bocs.fit(X,y)\n",
    "\n",
    "    # Random Search\n",
    "    rndS = RandomSearch(oracle=orc1, d=d)\n",
    "\n",
    "    # SMAC\n",
    "\n",
    "    # L2S-DISCO\n",
    "\n",
    "    BocsfList = [0]\n",
    "    RndList = [0]\n",
    "    for i in range(n1):\n",
    "        # BOCS\n",
    "        x_, y_ = bocs.update()\n",
    "        BocsfList.append(min(y_, min(BocsfList)))\n",
    "\n",
    "        # Random Search\n",
    "        x_, y_ = rndS.update()\n",
    "        RndList.append(min(y_, min(RndList)))\n",
    "    \n",
    "    # re-scale\n",
    "    y_MAX = max(max(BocsfList), max(RndList))\n",
    "    y_MIN = min(min(BocsfList), min(RndList))\n",
    "\n",
    "    # update\n",
    "    BocsfList = BocsfList / (y_MAX - y_MIN)\n",
    "    RndList = RndList / (y_MAX - y_MIN)\n",
    "\n",
    "    # update\n",
    "    dictBOCS[j] = BocsfList\n",
    "    dictRND[j]  = RndList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "626fa0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_MAX = max(max(BocsfList), max(RndList))\n",
    "y_MIN = min(min(BocsfList), min(RndList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "875589df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RANGE\n",
    "y_MAX = max(max(BocsfList), max(RndList))\n",
    "y_MIN = min(min(BocsfList), min(RndList))\n",
    "\n",
    "# update\n",
    "BocsfList = BocsfList / (y_MAX - y_MIN)\n",
    "RndList = RndList / (y_MAX - y_MIN)\n",
    "\n",
    "# Plot\n",
    "plt.plot(BocsfList / (y_MAX - y_MIN), color='darkblue')\n",
    "plt.plot(RndList / (y_MAX - y_MIN), color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe6cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMAC():\n",
    "    d_MAX = 20\n",
    "    \n",
    "    def __init__(self, oracle:Oracle, d:int, seed:int=0):\n",
    "        assert isinstance(d, int) and 0<d<self.d_MAX, f\"Dimension `d` must be non-negative integer smaller than {self.d_MAX}\"\n",
    "        \n",
    "        self.oracle = Oracle\n",
    "        self.d = d\n",
    "        self.seed = seed\n",
    "        \n",
    "        np.random.seed(self.seed)\n",
    "    \n",
    "    def update(self,):\n",
    "        '''\n",
    "        Sample random x (& noisy oracle function value) y\n",
    "        '''\n",
    "        return np.random.binomial(n=1, p=0.5, size=self.d)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcd55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
