{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b304ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0980d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(x:float):\n",
    "    '''\n",
    "    Not implemented\n",
    "    '''\n",
    "    return x\n",
    "\n",
    "def expected_improvement(mean:np.array, var:float, reference:np.array):\n",
    "    '''\n",
    "    EI for minimization problems\n",
    "    '''\n",
    "    k = len(mean)\n",
    "    \n",
    "    pred_normal = multivariate_normal(mean=np.zeros(k), cov=np.eye(k))\n",
    "    sigma = np.sqrt(var)\n",
    "    Z = (reference - mean) / sigma\n",
    "    \n",
    "    out = (sigma * np.exp(np.log(pred_normal.pdf(Z)))) + (-mean + reference) * pred_normal.cdf(Z)\n",
    "    out = out.clip(0)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "975048bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999680421156736"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_normal = multivariate_normal(mean=np.zeros(2), cov=np.eye(2))\n",
    "\n",
    "pred_normal.cdf(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de399647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.70302484, 3.59703581])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_improvement(np.array([0,0]), 4.5, np.array([3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12ef2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COMBO:\n",
    "    def __init__(obj, N_total:int=200, ):\n",
    "        acq_fun = expected_improvement\n",
    "        \n",
    "        # load objective\n",
    "        n_vertices = objective.n_vertices\n",
    "        adj_mat_list = objective.adjacency_mat\n",
    "        grouped_log_beta = torch.ones(len(objective.fourier_freq))\n",
    "        fourier_freq_list = objective.fourier_freq\n",
    "        fourier_basis_list = objective.fourier_basis\n",
    "        suggested_init = objective.suggested_init  # suggested_init should be 2d tensor\n",
    "        n_init = suggested_init.size(0)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def COMBO(objective=None, n_eval=200, dir_name=None, parallel=False, store_data=False, task='both', **kwargs):\n",
    "    \"\"\"\n",
    "    :param objective:\n",
    "    :param n_eval:\n",
    "    :param dir_name:\n",
    "    :param parallel:\n",
    "    :param store_data:\n",
    "    :param task:\n",
    "    :param kwargs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert task in ['suggest', 'evaluate', 'both']\n",
    "    # GOLD continues from info given in 'path' or starts minimization of 'objective'\n",
    "    assert (dir_name is None) != (objective is None)\n",
    "    acquisition_func = expected_improvement\n",
    "\n",
    "    # OBJECTIVTE \n",
    "    if objective is not None:\n",
    "        exp_dir = experiment_directory()\n",
    "        objective_id_list = [objective.__class__.__name__]\n",
    "        if hasattr(objective, 'random_seed_info'):\n",
    "            objective_id_list.append(objective.random_seed_info)\n",
    "        if hasattr(objective, 'lamda'):\n",
    "            objective_id_list.append('%.1E' % objective.lamda)\n",
    "        if hasattr(objective, 'data_type'):\n",
    "            objective_id_list.append(objective.data_type)\n",
    "        objective_id_list.append('COMBO')\n",
    "        objective_name = '_'.join(objective_id_list)\n",
    "        exp_dirname = bo_exp_dirname(exp_dir=exp_dir, objective_name=objective_name)\n",
    "\n",
    "        n_vertices = objective.n_vertices\n",
    "        adj_mat_list = objective.adjacency_mat\n",
    "        grouped_log_beta = torch.ones(len(objective.fourier_freq))\n",
    "        fourier_freq_list = objective.fourier_freq\n",
    "        fourier_basis_list = objective.fourier_basis\n",
    "        suggested_init = objective.suggested_init  # suggested_init should be 2d tensor\n",
    "        n_init = suggested_init.size(0)\n",
    "\n",
    "        kernel = DiffusionKernel(grouped_log_beta=grouped_log_beta,\n",
    "                                 fourier_freq_list=fourier_freq_list, fourier_basis_list=fourier_basis_list)\n",
    "        surrogate_model = GPRegression(kernel=kernel)\n",
    "\n",
    "        eval_inputs = suggested_init\n",
    "        eval_outputs = torch.zeros(eval_inputs.size(0), 1, device=eval_inputs.device)\n",
    "        for i in range(eval_inputs.size(0)):\n",
    "            eval_outputs[i] = objective.evaluate(eval_inputs[i])\n",
    "        assert not torch.isnan(eval_outputs).any()\n",
    "        log_beta = eval_outputs.new_zeros(eval_inputs.size(1))\n",
    "        sorted_partition = [[m] for m in range(eval_inputs.size(1))]\n",
    "\n",
    "        time_list = [time.time()] * n_init\n",
    "        elapse_list = [0] * n_init\n",
    "        pred_mean_list = [0] * n_init\n",
    "        pred_std_list = [0] * n_init\n",
    "        pred_var_list = [0] * n_init\n",
    "\n",
    "        surrogate_model.init_param(eval_outputs)\n",
    "        print('(%s) Burn-in' % time.strftime('%H:%M:%S', time.gmtime()))\n",
    "        sample_posterior = posterior_sampling(surrogate_model, eval_inputs, eval_outputs, n_vertices, adj_mat_list,\n",
    "                                              log_beta, sorted_partition, n_sample=1, n_burn=99, n_thin=1)\n",
    "        log_beta = sample_posterior[1][0]\n",
    "        sorted_partition = sample_posterior[2][0]\n",
    "        print('')\n",
    "\n",
    "        bo_data = {'surrogate_model': surrogate_model, 'eval_inputs': eval_inputs, 'eval_outputs': eval_outputs,\n",
    "                   'n_vertices': n_vertices, 'adj_mat_list': adj_mat_list, 'log_beta': log_beta,\n",
    "                   'sorted_partition': sorted_partition, 'time_list': time_list, 'elapse_list': elapse_list,\n",
    "                   'pred_mean_list': pred_mean_list, 'pred_std_list': pred_std_list, 'pred_var_list': pred_var_list,\n",
    "                   'acquisition_func': acquisition_func, 'objective': objective}\n",
    "        torch.save(bo_data, os.path.join(exp_dirname, 'bo_data.pt'))\n",
    "\n",
    "    eval_cnt = 0\n",
    "    while eval_cnt < n_eval:\n",
    "        # RUN BO\n",
    "        eval_cnt = run_bo(exp_dirname=dir_name if objective is None else exp_dirname,\n",
    "                          store_data=store_data, task=task, parallel=parallel)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
